{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install spikingjelly\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.utils.data as data\nimport torchvision\nimport torch\nimport numpy as np\nfrom spikingjelly.clock_driven import neuron, encoding, functional\nfrom torch.utils.tensorboard import SummaryWriter\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt ","metadata":{"execution":{"iopub.status.busy":"2022-02-25T19:20:51.755904Z","iopub.execute_input":"2022-02-25T19:20:51.756458Z","iopub.status.idle":"2022-02-25T19:21:07.171379Z","shell.execute_reply.started":"2022-02-25T19:20:51.756350Z","shell.execute_reply":"2022-02-25T19:21:07.170639Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"### variables","metadata":{}},{"cell_type":"code","source":"device = 'cuda:0'\ndataset_dir = './'\nlog_dir = './'\nmodel_output_dir = './'\nbatch_size = 32\nlr = 1e-3\nT = 100\n# T = timesteps\ntau = 2.0\n#tau = tau m \ntrain_epoch = 2\nwriter = SummaryWriter(log_dir)","metadata":{"execution":{"iopub.status.busy":"2022-02-25T19:21:07.173145Z","iopub.execute_input":"2022-02-25T19:21:07.173402Z","iopub.status.idle":"2022-02-25T19:21:11.170352Z","shell.execute_reply.started":"2022-02-25T19:21:07.173370Z","shell.execute_reply":"2022-02-25T19:21:11.169628Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":" \n\\begin{align}\\begin{aligned}\\tau_{m} \\frac{\\mathrm{d}V(t)}{\\mathrm{d}t} = -(V(t) - V_{reset}) + X(t)\\\\\\tau_{m} (V(t) - V(t-1)) = -(V(t-1) - V_{reset}) + X(t)\\end{aligned}\\end{align}\n##  \n![lif](https://www.researchgate.net/publication/339574089/figure/fig1/AS:863726592872448@1582939875128/The-illustration-of-Leaky-Integrate-and-Fire-LIF-neuron-dynamics-The-pre-spikes-are.png)","metadata":{}},{"cell_type":"markdown","source":"### loading dataset","metadata":{}},{"cell_type":"code","source":"train_dataset = torchvision.datasets.MNIST(\n        root=dataset_dir,\n        train=True,\n        transform=torchvision.transforms.ToTensor(),\n        download=True\n)\ntest_dataset = torchvision.datasets.MNIST(\n        root=dataset_dir,\n        train=False,\n        transform=torchvision.transforms.ToTensor(),\n        download=True\n)\n\ntrain_data_loader = data.DataLoader(\n        dataset=train_dataset,\n        batch_size=batch_size,\n        shuffle=True,\n        drop_last=True\n)\ntest_data_loader = data.DataLoader(\n        dataset=test_dataset,\n        batch_size=batch_size,\n        shuffle=False,\n        drop_last=False\n)","metadata":{"execution":{"iopub.status.busy":"2022-02-25T19:21:11.171727Z","iopub.execute_input":"2022-02-25T19:21:11.171956Z","iopub.status.idle":"2022-02-25T19:21:13.199082Z","shell.execute_reply.started":"2022-02-25T19:21:11.171923Z","shell.execute_reply":"2022-02-25T19:21:13.197965Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"### define model","metadata":{}},{"cell_type":"code","source":"net = nn.Sequential(\n        nn.Flatten(),\n        nn.Linear(28*28, 100, bias=False),\n        neuron.LIFNode(tau=tau),\n        nn.Linear(100, 10, bias=False),\n        neuron.LIFNode(tau=tau)\n\n)\nnet = net.to(device)\n    # optimizer\noptimizer = torch.optim.Adam(net.parameters(), lr=lr)\n    #define encoder\nencoder = encoding.PoissonEncoder()\ntrain_times = 0\nmax_test_accuracy = 0","metadata":{"execution":{"iopub.status.busy":"2022-02-25T19:21:13.201191Z","iopub.execute_input":"2022-02-25T19:21:13.201686Z","iopub.status.idle":"2022-02-25T19:21:17.734860Z","shell.execute_reply.started":"2022-02-25T19:21:13.201641Z","shell.execute_reply":"2022-02-25T19:21:17.734079Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"### training","metadata":{}},{"cell_type":"code","source":"test_accs = []\ntrain_accs = []\nlosses= []\nfor epoch in range(train_epoch):\n        print(\"Epoch {}:\".format(epoch))\n        train_correct_sum = 0\n        train_sum = 0\n        net.train()\n        for img, label in tqdm(train_data_loader):\n            img = img.to(device)\n            label = label.to(device)\n            label_one_hot = F.one_hot(label, 10).float()\n\n            optimizer.zero_grad()\n\n            for t in range(T):\n                if t == 0:\n                    # encode and train one step\n                    out_spikes_counter = net(encoder(img).float())\n\n                else:\n                    out_spikes_counter += net(encoder(img).float())\n            #check the spikes frequency \n            out_spikes_counter_frequency = out_spikes_counter / T\n            # calculate the mse i think mse is better then cross entropy\n            loss = F.mse_loss(out_spikes_counter_frequency, label_one_hot)\n            # backward probagation \n            losses.append(loss)\n            loss.backward()\n            optimizer.step()\n            functional.reset_net(net)\n            #losses.append(loss)\n            #metrics calulations\n            train_correct_sum += (out_spikes_counter_frequency.max(1)[1] == label.to(device)).float().sum().item()\n            train_sum += label.numel()\n\n            train_batch_accuracy = (out_spikes_counter_frequency.max(1)[1] == label.to(device)).float().mean().item()\n            writer.add_scalar('train_batch_accuracy', train_batch_accuracy, train_times)\n            train_accs.append(train_batch_accuracy)\n\n            train_times += 1\n        # the mean of the accuracy \n        train_accuracy = train_correct_sum / train_sum\n        net.eval()\n        with torch.no_grad():\n            test_correct_sum = 0\n            test_sum = 0\n            for img, label in tqdm(test_data_loader):\n                img = img.to(device)\n                for t in range(T):\n                    if t == 0:\n                        im = encoder(img)\n                        out_spikes_counter = net(im.float())\n                    else:\n                        im = encoder(img)\n                        out_spikes_counter += net(im.float())\n\n                test_correct_sum += (out_spikes_counter.max(1)[1] == label.to(device)).float().sum().item()\n                test_sum += label.numel()\n                functional.reset_net(net)\n            test_accuracy = test_correct_sum / test_sum\n            writer.add_scalar('test_accuracy', test_accuracy, epoch)\n            test_accs.append(test_accuracy)\n            max_test_accuracy = max(max_test_accuracy, test_accuracy)\n        print(\"train_acc = {}, test_acc={}, max_test_acc={}, train_times={}\".format( train_accuracy, test_accuracy, max_test_accuracy, train_times))","metadata":{"execution":{"iopub.status.busy":"2022-02-25T19:21:17.736235Z","iopub.execute_input":"2022-02-25T19:21:17.736634Z","iopub.status.idle":"2022-02-25T19:28:47.473025Z","shell.execute_reply.started":"2022-02-25T19:21:17.736596Z","shell.execute_reply":"2022-02-25T19:28:47.472293Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"### learning curves","metadata":{}},{"cell_type":"code","source":"plt.figure()\nplt.plot(train_accs,\"r\")\nplt.xlabel(\"timestamps\")\nplt.title('train accuracy')\nplt.figure()\nplt.plot(test_accs)\nplt.title(\"test accuracy\")\nplt.figure()\nplt.plot(list(map(lambda x: x.cpu().detach().numpy(),losses)))\nplt.title(\"train losses\")","metadata":{"execution":{"iopub.status.busy":"2022-02-25T19:28:47.474076Z","iopub.execute_input":"2022-02-25T19:28:47.474297Z","iopub.status.idle":"2022-02-25T19:28:48.112163Z","shell.execute_reply.started":"2022-02-25T19:28:47.474271Z","shell.execute_reply":"2022-02-25T19:28:48.111412Z"},"trusted":true},"execution_count":6,"outputs":[]}]}