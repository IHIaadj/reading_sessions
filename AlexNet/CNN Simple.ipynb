{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem when dealing with larger dataset is the overfitting encoutered when using MLP. The overfitting is the behavior of not generalizing well to non-training data. \n",
    "\n",
    "![](images/overfitting.png)\n",
    "\n",
    "We will introduce a popular kind of model called **Convolutional neural networks** that is specially good for processing images. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "train_dataset = datasets.MNIST('./data', \n",
    "                               train=True, \n",
    "                               download=True, \n",
    "                               transform=transforms.ToTensor())\n",
    "\n",
    "valid_dataset = datasets.MNIST('./data', \n",
    "                                    train=False, \n",
    "                                    transform=transforms.ToTensor())\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "valid_loader = torch.utils.data.DataLoader(dataset=valid_dataset, \n",
    "                                                batch_size=batch_size, \n",
    "                                                shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_dataset.data[0], cmap='gray')\n",
    "plt.title('%i' % train_dataset.targets[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The architecture of the CNN is composed of several operations. \n",
    "\n",
    "![](images/cnn.jpeg)\n",
    "Source: https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Sequential(         \n",
    "            nn.Conv2d(\n",
    "                in_channels=1,              \n",
    "                out_channels=16,            \n",
    "                kernel_size=5,              \n",
    "                stride=1,                   \n",
    "                padding=2,                  \n",
    "            ),                              \n",
    "            nn.ReLU(),                      \n",
    "            nn.MaxPool2d(kernel_size=2),    \n",
    "        )\n",
    "        self.conv2 = nn.Sequential(         \n",
    "            nn.Conv2d(16, 32, 5, 1, 2),     \n",
    "            nn.ReLU(),                      \n",
    "            nn.MaxPool2d(2),                \n",
    "        )        \n",
    "        \n",
    "        # fully connected layer, output 10 classes\n",
    "        self.out = nn.Linear(32 * 7 * 7, 10)    \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)        \n",
    "        # flatten the output of conv2 to (batch_size, 32 * 7 * 7)\n",
    "        x = x.view(x.size(0), -1)       \n",
    "        output = self.out(x)\n",
    "        return output, x    # return x for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (out): Linear(in_features=1568, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "cnn = CNN()\n",
    "print(cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.CrossEntropyLoss() \n",
    "optimizer = optim.Adam(cnn.parameters(), lr = 0.01) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [100/1875], Loss: 0.0397\n",
      "Epoch [1/10], Step [200/1875], Loss: 0.1628\n",
      "Epoch [1/10], Step [300/1875], Loss: 0.0253\n",
      "Epoch [1/10], Step [400/1875], Loss: 0.0150\n",
      "Epoch [1/10], Step [500/1875], Loss: 0.4441\n",
      "Epoch [1/10], Step [600/1875], Loss: 0.0630\n",
      "Epoch [1/10], Step [700/1875], Loss: 0.4389\n",
      "Epoch [1/10], Step [800/1875], Loss: 0.0004\n",
      "Epoch [1/10], Step [900/1875], Loss: 0.0604\n",
      "Epoch [1/10], Step [1000/1875], Loss: 0.0321\n",
      "Epoch [1/10], Step [1100/1875], Loss: 0.2176\n",
      "Epoch [1/10], Step [1200/1875], Loss: 0.1992\n",
      "Epoch [1/10], Step [1300/1875], Loss: 0.0758\n",
      "Epoch [1/10], Step [1400/1875], Loss: 0.1028\n",
      "Epoch [1/10], Step [1500/1875], Loss: 0.0101\n",
      "Epoch [1/10], Step [1600/1875], Loss: 0.2153\n",
      "Epoch [1/10], Step [1700/1875], Loss: 0.0144\n",
      "Epoch [1/10], Step [1800/1875], Loss: 0.0601\n",
      "Epoch [2/10], Step [100/1875], Loss: 0.0271\n",
      "Epoch [2/10], Step [200/1875], Loss: 0.1383\n",
      "Epoch [2/10], Step [300/1875], Loss: 0.0944\n",
      "Epoch [2/10], Step [400/1875], Loss: 0.1262\n",
      "Epoch [2/10], Step [500/1875], Loss: 0.0184\n",
      "Epoch [2/10], Step [600/1875], Loss: 0.2205\n",
      "Epoch [2/10], Step [700/1875], Loss: 0.1855\n",
      "Epoch [2/10], Step [800/1875], Loss: 0.0117\n",
      "Epoch [2/10], Step [900/1875], Loss: 0.2535\n",
      "Epoch [2/10], Step [1000/1875], Loss: 0.0232\n",
      "Epoch [2/10], Step [1100/1875], Loss: 0.1889\n",
      "Epoch [2/10], Step [1200/1875], Loss: 0.0046\n",
      "Epoch [2/10], Step [1300/1875], Loss: 0.0076\n",
      "Epoch [2/10], Step [1400/1875], Loss: 0.0991\n",
      "Epoch [2/10], Step [1500/1875], Loss: 0.0026\n",
      "Epoch [2/10], Step [1600/1875], Loss: 0.0051\n",
      "Epoch [2/10], Step [1700/1875], Loss: 0.2983\n",
      "Epoch [2/10], Step [1800/1875], Loss: 0.0040\n",
      "Epoch [3/10], Step [100/1875], Loss: 0.4415\n",
      "Epoch [3/10], Step [200/1875], Loss: 0.0008\n",
      "Epoch [3/10], Step [300/1875], Loss: 0.0008\n",
      "Epoch [3/10], Step [400/1875], Loss: 0.1927\n",
      "Epoch [3/10], Step [500/1875], Loss: 0.0099\n",
      "Epoch [3/10], Step [600/1875], Loss: 0.0018\n",
      "Epoch [3/10], Step [700/1875], Loss: 0.0091\n",
      "Epoch [3/10], Step [800/1875], Loss: 0.0015\n",
      "Epoch [3/10], Step [900/1875], Loss: 0.0091\n",
      "Epoch [3/10], Step [1000/1875], Loss: 0.0194\n",
      "Epoch [3/10], Step [1100/1875], Loss: 0.1046\n",
      "Epoch [3/10], Step [1200/1875], Loss: 0.0295\n",
      "Epoch [3/10], Step [1300/1875], Loss: 0.1374\n",
      "Epoch [3/10], Step [1400/1875], Loss: 0.0004\n",
      "Epoch [3/10], Step [1500/1875], Loss: 0.1406\n",
      "Epoch [3/10], Step [1600/1875], Loss: 0.2494\n",
      "Epoch [3/10], Step [1700/1875], Loss: 0.2645\n",
      "Epoch [3/10], Step [1800/1875], Loss: 0.1261\n",
      "Epoch [4/10], Step [100/1875], Loss: 0.0278\n",
      "Epoch [4/10], Step [200/1875], Loss: 0.0002\n",
      "Epoch [4/10], Step [300/1875], Loss: 0.1142\n",
      "Epoch [4/10], Step [400/1875], Loss: 0.0033\n",
      "Epoch [4/10], Step [500/1875], Loss: 0.1946\n",
      "Epoch [4/10], Step [600/1875], Loss: 0.0085\n",
      "Epoch [4/10], Step [700/1875], Loss: 0.0010\n",
      "Epoch [4/10], Step [800/1875], Loss: 0.0028\n",
      "Epoch [4/10], Step [900/1875], Loss: 0.0695\n",
      "Epoch [4/10], Step [1000/1875], Loss: 0.0078\n",
      "Epoch [4/10], Step [1100/1875], Loss: 0.0140\n",
      "Epoch [4/10], Step [1200/1875], Loss: 0.2215\n",
      "Epoch [4/10], Step [1300/1875], Loss: 0.0018\n",
      "Epoch [4/10], Step [1400/1875], Loss: 0.0017\n",
      "Epoch [4/10], Step [1500/1875], Loss: 0.0310\n",
      "Epoch [4/10], Step [1600/1875], Loss: 0.0443\n",
      "Epoch [4/10], Step [1700/1875], Loss: 0.0010\n",
      "Epoch [4/10], Step [1800/1875], Loss: 0.0045\n",
      "Epoch [5/10], Step [100/1875], Loss: 0.0001\n",
      "Epoch [5/10], Step [200/1875], Loss: 0.0009\n",
      "Epoch [5/10], Step [300/1875], Loss: 0.0154\n",
      "Epoch [5/10], Step [400/1875], Loss: 0.0570\n",
      "Epoch [5/10], Step [500/1875], Loss: 0.0006\n",
      "Epoch [5/10], Step [600/1875], Loss: 0.1451\n",
      "Epoch [5/10], Step [700/1875], Loss: 0.2928\n",
      "Epoch [5/10], Step [800/1875], Loss: 0.2812\n",
      "Epoch [5/10], Step [900/1875], Loss: 0.1616\n",
      "Epoch [5/10], Step [1000/1875], Loss: 0.0618\n",
      "Epoch [5/10], Step [1100/1875], Loss: 0.0021\n",
      "Epoch [5/10], Step [1200/1875], Loss: 0.4754\n",
      "Epoch [5/10], Step [1300/1875], Loss: 0.0002\n",
      "Epoch [5/10], Step [1400/1875], Loss: 0.0069\n",
      "Epoch [5/10], Step [1500/1875], Loss: 0.0712\n",
      "Epoch [5/10], Step [1600/1875], Loss: 0.0006\n",
      "Epoch [5/10], Step [1700/1875], Loss: 0.0776\n",
      "Epoch [5/10], Step [1800/1875], Loss: 0.0045\n",
      "Epoch [6/10], Step [100/1875], Loss: 0.0325\n",
      "Epoch [6/10], Step [200/1875], Loss: 0.0004\n",
      "Epoch [6/10], Step [300/1875], Loss: 0.0002\n",
      "Epoch [6/10], Step [400/1875], Loss: 0.0005\n",
      "Epoch [6/10], Step [500/1875], Loss: 0.0532\n",
      "Epoch [6/10], Step [600/1875], Loss: 0.5638\n",
      "Epoch [6/10], Step [700/1875], Loss: 0.0057\n",
      "Epoch [6/10], Step [800/1875], Loss: 0.1202\n",
      "Epoch [6/10], Step [900/1875], Loss: 0.0014\n",
      "Epoch [6/10], Step [1000/1875], Loss: 0.0003\n",
      "Epoch [6/10], Step [1100/1875], Loss: 0.3917\n",
      "Epoch [6/10], Step [1200/1875], Loss: 0.0251\n",
      "Epoch [6/10], Step [1300/1875], Loss: 0.2137\n",
      "Epoch [6/10], Step [1400/1875], Loss: 0.0041\n",
      "Epoch [6/10], Step [1500/1875], Loss: 0.0361\n",
      "Epoch [6/10], Step [1600/1875], Loss: 0.0753\n",
      "Epoch [6/10], Step [1700/1875], Loss: 0.0949\n",
      "Epoch [6/10], Step [1800/1875], Loss: 0.0209\n",
      "Epoch [7/10], Step [100/1875], Loss: 0.4401\n",
      "Epoch [7/10], Step [200/1875], Loss: 0.0003\n",
      "Epoch [7/10], Step [300/1875], Loss: 0.0020\n",
      "Epoch [7/10], Step [400/1875], Loss: 0.0530\n",
      "Epoch [7/10], Step [500/1875], Loss: 0.0022\n",
      "Epoch [7/10], Step [600/1875], Loss: 0.0273\n",
      "Epoch [7/10], Step [700/1875], Loss: 0.0002\n",
      "Epoch [7/10], Step [800/1875], Loss: 0.0074\n",
      "Epoch [7/10], Step [900/1875], Loss: 0.0000\n",
      "Epoch [7/10], Step [1000/1875], Loss: 0.2853\n",
      "Epoch [7/10], Step [1100/1875], Loss: 0.1944\n",
      "Epoch [7/10], Step [1200/1875], Loss: 0.0005\n",
      "Epoch [7/10], Step [1300/1875], Loss: 0.1914\n",
      "Epoch [7/10], Step [1400/1875], Loss: 0.0008\n",
      "Epoch [7/10], Step [1500/1875], Loss: 0.0841\n",
      "Epoch [7/10], Step [1600/1875], Loss: 0.1136\n",
      "Epoch [7/10], Step [1700/1875], Loss: 0.0124\n",
      "Epoch [7/10], Step [1800/1875], Loss: 0.0031\n",
      "Epoch [8/10], Step [100/1875], Loss: 0.0007\n",
      "Epoch [8/10], Step [200/1875], Loss: 0.0333\n",
      "Epoch [8/10], Step [300/1875], Loss: 0.0000\n",
      "Epoch [8/10], Step [400/1875], Loss: 0.0002\n",
      "Epoch [8/10], Step [500/1875], Loss: 0.0015\n",
      "Epoch [8/10], Step [600/1875], Loss: 0.0028\n",
      "Epoch [8/10], Step [700/1875], Loss: 0.0330\n",
      "Epoch [8/10], Step [800/1875], Loss: 0.0146\n",
      "Epoch [8/10], Step [900/1875], Loss: 0.2729\n",
      "Epoch [8/10], Step [1000/1875], Loss: 0.1710\n",
      "Epoch [8/10], Step [1100/1875], Loss: 0.0003\n",
      "Epoch [8/10], Step [1200/1875], Loss: 0.0007\n",
      "Epoch [8/10], Step [1300/1875], Loss: 0.0142\n",
      "Epoch [8/10], Step [1400/1875], Loss: 0.0001\n",
      "Epoch [8/10], Step [1500/1875], Loss: 0.0010\n",
      "Epoch [8/10], Step [1600/1875], Loss: 0.0235\n",
      "Epoch [8/10], Step [1700/1875], Loss: 0.0002\n",
      "Epoch [8/10], Step [1800/1875], Loss: 0.0312\n",
      "Epoch [9/10], Step [100/1875], Loss: 0.0040\n",
      "Epoch [9/10], Step [200/1875], Loss: 0.0001\n",
      "Epoch [9/10], Step [300/1875], Loss: 0.0005\n",
      "Epoch [9/10], Step [400/1875], Loss: 0.0088\n",
      "Epoch [9/10], Step [500/1875], Loss: 0.1090\n",
      "Epoch [9/10], Step [600/1875], Loss: 0.0034\n",
      "Epoch [9/10], Step [700/1875], Loss: 0.3022\n",
      "Epoch [9/10], Step [800/1875], Loss: 0.3992\n",
      "Epoch [9/10], Step [900/1875], Loss: 0.0103\n",
      "Epoch [9/10], Step [1000/1875], Loss: 0.0085\n",
      "Epoch [9/10], Step [1100/1875], Loss: 0.2630\n",
      "Epoch [9/10], Step [1200/1875], Loss: 0.0051\n",
      "Epoch [9/10], Step [1300/1875], Loss: 0.0223\n",
      "Epoch [9/10], Step [1400/1875], Loss: 0.0031\n",
      "Epoch [9/10], Step [1500/1875], Loss: 0.5293\n",
      "Epoch [9/10], Step [1600/1875], Loss: 0.1710\n",
      "Epoch [9/10], Step [1700/1875], Loss: 0.0123\n",
      "Epoch [9/10], Step [1800/1875], Loss: 0.0707\n",
      "Epoch [10/10], Step [100/1875], Loss: 0.0254\n",
      "Epoch [10/10], Step [200/1875], Loss: 0.0526\n",
      "Epoch [10/10], Step [300/1875], Loss: 0.0000\n",
      "Epoch [10/10], Step [400/1875], Loss: 0.0046\n",
      "Epoch [10/10], Step [500/1875], Loss: 0.0030\n",
      "Epoch [10/10], Step [600/1875], Loss: 0.0016\n",
      "Epoch [10/10], Step [700/1875], Loss: 0.0000\n",
      "Epoch [10/10], Step [800/1875], Loss: 0.0083\n",
      "Epoch [10/10], Step [900/1875], Loss: 0.0452\n",
      "Epoch [10/10], Step [1000/1875], Loss: 0.2455\n",
      "Epoch [10/10], Step [1100/1875], Loss: 0.0175\n",
      "Epoch [10/10], Step [1200/1875], Loss: 0.0567\n",
      "Epoch [10/10], Step [1300/1875], Loss: 0.0022\n",
      "Epoch [10/10], Step [1400/1875], Loss: 0.1232\n",
      "Epoch [10/10], Step [1500/1875], Loss: 0.3262\n",
      "Epoch [10/10], Step [1600/1875], Loss: 0.0022\n",
      "Epoch [10/10], Step [1700/1875], Loss: 0.3920\n",
      "Epoch [10/10], Step [1800/1875], Loss: 0.0000\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "\n",
    "def train(num_epochs, cnn):\n",
    "    \n",
    "    cnn.train()\n",
    "        \n",
    "    # Train the model\n",
    "    total_step = len(train_loader)\n",
    "        \n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            \n",
    "            # gives batch data, normalize x when iterate train_loader\n",
    "            b_x = Variable(images)   # batch x\n",
    "            b_y = Variable(labels)   # batch y\n",
    "            output = cnn(b_x)[0]               \n",
    "            loss = loss_func(output, b_y)\n",
    "            \n",
    "            # clear gradients for this training step   \n",
    "            optimizer.zero_grad()           \n",
    "            \n",
    "            # backpropagation, compute gradients \n",
    "            loss.backward()                # apply gradients             \n",
    "            optimizer.step()                \n",
    "            \n",
    "            if (i+1) % 100 == 0:\n",
    "                print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                       .format(epoch + 1, num_epochs, i + 1, total_step, loss.item()))               \n",
    "                pass\n",
    "        pass\n",
    "    pass\n",
    "    \n",
    "train(num_epochs, cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on the 10000 test images: 1.00\n"
     ]
    }
   ],
   "source": [
    "def validate():\n",
    "    cnn.eval()    \n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in valid_loader:\n",
    "            test_output, last_layer = cnn(images)\n",
    "            pred_y = torch.max(test_output, 1)[1].data.squeeze()\n",
    "            accuracy = (pred_y == labels).sum().item() / float(labels.size(0))\n",
    "            pass\n",
    "        print('Test Accuracy of the model on the 10000 test images: %.2f' % accuracy)\n",
    "    \n",
    "    pass\n",
    "\n",
    "validate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
