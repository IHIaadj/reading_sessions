{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2nd reading session in the 2022/23 season \n",
    "In this session we have read this paper [Tabular Data: Deep Learning is Not All You Need]( https://arxiv.org/abs/2106.03253)\n",
    "And we have decided to get our hands dirty with the code by training the XGB boost with the used parameters in the paper and the TabNet model that is cited in this paper then Ms.Hajer Benmeziane gaved us a challenge to combine (ensemble) the TabNet model the XGB boost one.In this notebook I have tried to use some Weighted Average Ensemble techniques and compare the results at the end in a table.  <br />\n",
    "**Note : that we have trained both models on the Covertype dataset**\n",
    "### The papers's abstract\n",
    ">  A key element in solving real-life data science problems is selecting the types of models to use.\n",
    "Tree ensemble models (such as XGBoost) are usually recommended for classification and regression\n",
    "problems with tabular data. However, several deep learning models for tabular data have recently been\n",
    "proposed, claiming to outperform XGBoost for some use cases. This paper explores whether these\n",
    "deep models should be a recommended option for tabular data by rigorously comparing the new deep\n",
    "models to XGBoost on various datasets. In addition to systematically comparing their performance,\n",
    "we consider the tuning and computation they require. Our study shows that XGBoost outperforms\n",
    "these deep models across the datasets, including the datasets used in the papers that proposed the\n",
    "deep models. We also demonstrate that XGBoost requires much less tuning. On the positive side, we\n",
    "show that an ensemble of deep models and XGBoost performs better on these datasets than XGBoost\n",
    "alone.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data and packages imports and checking\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tabulate\n",
    "\n",
    "import torch\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_names = [            \n",
    "    \"Elevation\",\n",
    "    \"Aspect\",\n",
    "    \"Slope\",\n",
    "    \"R_Hydrology\",\n",
    "    \"Z_Hydrology\",\n",
    "    \"R_Roadways\",\n",
    "    \"Hillshade_9am\",\n",
    "    \"Hillshade_Noon\",\n",
    "    \"Hillshade_3pm\",\n",
    "    \"R_Fire_Points\",\n",
    "] # Continuous variables\n",
    "\n",
    "cont_dict = {name: np.float64 for name in cont_names}\n",
    "area_names = ['Wilderness_Area' + str(i + 1) for i in range(4)]\n",
    "area_dict = {name: np.int64 for name in area_names}\n",
    "soil_names = ['Soil_Type' + str(i + 1) for i in range(40)]\n",
    "soil_dict = {name: np.int64 for name in soil_names}\n",
    "bin_names = area_names + soil_names\n",
    "\n",
    "target = 'Cover_Type'\n",
    "\n",
    "names = cont_names + bin_names # All column names except target\n",
    "dtypes_dict = {**cont_dict, **area_dict, **soil_dict}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Elevation</th>\n",
       "      <th>Aspect</th>\n",
       "      <th>Slope</th>\n",
       "      <th>R_Hydrology</th>\n",
       "      <th>Z_Hydrology</th>\n",
       "      <th>R_Roadways</th>\n",
       "      <th>Hillshade_9am</th>\n",
       "      <th>Hillshade_Noon</th>\n",
       "      <th>Hillshade_3pm</th>\n",
       "      <th>R_Fire_Points</th>\n",
       "      <th>...</th>\n",
       "      <th>Soil_Type32</th>\n",
       "      <th>Soil_Type33</th>\n",
       "      <th>Soil_Type34</th>\n",
       "      <th>Soil_Type35</th>\n",
       "      <th>Soil_Type36</th>\n",
       "      <th>Soil_Type37</th>\n",
       "      <th>Soil_Type38</th>\n",
       "      <th>Soil_Type39</th>\n",
       "      <th>Soil_Type40</th>\n",
       "      <th>Cover_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2596.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>258.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>510.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>232.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>6279.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2590.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>390.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>6225.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2804.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>268.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>3180.0</td>\n",
       "      <td>234.0</td>\n",
       "      <td>238.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>6121.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2785.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>3090.0</td>\n",
       "      <td>238.0</td>\n",
       "      <td>238.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>6211.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2595.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>391.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>234.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>6172.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Elevation  Aspect  Slope  R_Hydrology  Z_Hydrology  R_Roadways  \\\n",
       "0     2596.0    51.0    3.0        258.0          0.0       510.0   \n",
       "1     2590.0    56.0    2.0        212.0         -6.0       390.0   \n",
       "2     2804.0   139.0    9.0        268.0         65.0      3180.0   \n",
       "3     2785.0   155.0   18.0        242.0        118.0      3090.0   \n",
       "4     2595.0    45.0    2.0        153.0         -1.0       391.0   \n",
       "\n",
       "   Hillshade_9am  Hillshade_Noon  Hillshade_3pm  R_Fire_Points  ...  \\\n",
       "0          221.0           232.0          148.0         6279.0  ...   \n",
       "1          220.0           235.0          151.0         6225.0  ...   \n",
       "2          234.0           238.0          135.0         6121.0  ...   \n",
       "3          238.0           238.0          122.0         6211.0  ...   \n",
       "4          220.0           234.0          150.0         6172.0  ...   \n",
       "\n",
       "   Soil_Type32  Soil_Type33  Soil_Type34  Soil_Type35  Soil_Type36  \\\n",
       "0            0            0            0            0            0   \n",
       "1            0            0            0            0            0   \n",
       "2            0            0            0            0            0   \n",
       "3            0            0            0            0            0   \n",
       "4            0            0            0            0            0   \n",
       "\n",
       "   Soil_Type37  Soil_Type38  Soil_Type39  Soil_Type40  Cover_Type  \n",
       "0            0            0            0            0           5  \n",
       "1            0            0            0            0           5  \n",
       "2            0            0            0            0           2  \n",
       "3            0            0            0            0           2  \n",
       "4            0            0            0            0           5  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('covtype.data', header=None, names=names + [target], dtype=dtypes_dict)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 581012 entries, 0 to 581011\n",
      "Data columns (total 55 columns):\n",
      " #   Column            Non-Null Count   Dtype  \n",
      "---  ------            --------------   -----  \n",
      " 0   Elevation         581012 non-null  float64\n",
      " 1   Aspect            581012 non-null  float64\n",
      " 2   Slope             581012 non-null  float64\n",
      " 3   R_Hydrology       581012 non-null  float64\n",
      " 4   Z_Hydrology       581012 non-null  float64\n",
      " 5   R_Roadways        581012 non-null  float64\n",
      " 6   Hillshade_9am     581012 non-null  float64\n",
      " 7   Hillshade_Noon    581012 non-null  float64\n",
      " 8   Hillshade_3pm     581012 non-null  float64\n",
      " 9   R_Fire_Points     581012 non-null  float64\n",
      " 10  Wilderness_Area1  581012 non-null  int64  \n",
      " 11  Wilderness_Area2  581012 non-null  int64  \n",
      " 12  Wilderness_Area3  581012 non-null  int64  \n",
      " 13  Wilderness_Area4  581012 non-null  int64  \n",
      " 14  Soil_Type1        581012 non-null  int64  \n",
      " 15  Soil_Type2        581012 non-null  int64  \n",
      " 16  Soil_Type3        581012 non-null  int64  \n",
      " 17  Soil_Type4        581012 non-null  int64  \n",
      " 18  Soil_Type5        581012 non-null  int64  \n",
      " 19  Soil_Type6        581012 non-null  int64  \n",
      " 20  Soil_Type7        581012 non-null  int64  \n",
      " 21  Soil_Type8        581012 non-null  int64  \n",
      " 22  Soil_Type9        581012 non-null  int64  \n",
      " 23  Soil_Type10       581012 non-null  int64  \n",
      " 24  Soil_Type11       581012 non-null  int64  \n",
      " 25  Soil_Type12       581012 non-null  int64  \n",
      " 26  Soil_Type13       581012 non-null  int64  \n",
      " 27  Soil_Type14       581012 non-null  int64  \n",
      " 28  Soil_Type15       581012 non-null  int64  \n",
      " 29  Soil_Type16       581012 non-null  int64  \n",
      " 30  Soil_Type17       581012 non-null  int64  \n",
      " 31  Soil_Type18       581012 non-null  int64  \n",
      " 32  Soil_Type19       581012 non-null  int64  \n",
      " 33  Soil_Type20       581012 non-null  int64  \n",
      " 34  Soil_Type21       581012 non-null  int64  \n",
      " 35  Soil_Type22       581012 non-null  int64  \n",
      " 36  Soil_Type23       581012 non-null  int64  \n",
      " 37  Soil_Type24       581012 non-null  int64  \n",
      " 38  Soil_Type25       581012 non-null  int64  \n",
      " 39  Soil_Type26       581012 non-null  int64  \n",
      " 40  Soil_Type27       581012 non-null  int64  \n",
      " 41  Soil_Type28       581012 non-null  int64  \n",
      " 42  Soil_Type29       581012 non-null  int64  \n",
      " 43  Soil_Type30       581012 non-null  int64  \n",
      " 44  Soil_Type31       581012 non-null  int64  \n",
      " 45  Soil_Type32       581012 non-null  int64  \n",
      " 46  Soil_Type33       581012 non-null  int64  \n",
      " 47  Soil_Type34       581012 non-null  int64  \n",
      " 48  Soil_Type35       581012 non-null  int64  \n",
      " 49  Soil_Type36       581012 non-null  int64  \n",
      " 50  Soil_Type37       581012 non-null  int64  \n",
      " 51  Soil_Type38       581012 non-null  int64  \n",
      " 52  Soil_Type39       581012 non-null  int64  \n",
      " 53  Soil_Type40       581012 non-null  int64  \n",
      " 54  Cover_Type        581012 non-null  int64  \n",
      "dtypes: float64(10), int64(45)\n",
      "memory usage: 243.8 MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape : (581012, 55)\n"
     ]
    }
   ],
   "source": [
    "print('data shape :', data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_total = len(data)\n",
    "\n",
    "train_val_indices, test_indices = train_test_split(\n",
    "    range(n_total), test_size=0.2, random_state=0)\n",
    "train_indices, valid_indices = train_test_split(\n",
    "    train_val_indices, test_size=0.2 / 0.6, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = []\n",
    "categorical_dims =  {}\n",
    "for col in data.columns[data.dtypes == object]:\n",
    "    print(col, data[col].nunique())\n",
    "    l_enc = LabelEncoder()\n",
    "    data[col] = data[col].fillna(\"VV_likely\")\n",
    "    data[col] = l_enc.fit_transform(data[col].values)\n",
    "    categorical_columns.append(col)\n",
    "    categorical_dims[col] = len(l_enc.classes_)\n",
    "\n",
    "for col in data.columns[data.dtypes == 'float64']:\n",
    "    data.fillna(data.loc[train_indices, col].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "unused_feat = []\n",
    "\n",
    "features = [ col for col in data.columns if col not in unused_feat+[target]] \n",
    "\n",
    "cat_idxs = [ i for i, f in enumerate(features) if f in categorical_columns]\n",
    "\n",
    "cat_dims = [ categorical_dims[f] for i, f in enumerate(features) if f in categorical_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TabNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MON PC\\AppData\\Roaming\\Python\\Python310\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    }
   ],
   "source": [
    "model = TabNetClassifier(\n",
    "    n_d=64, n_a=64, n_steps=5,\n",
    "    gamma=1.5, n_independent=2, n_shared=2,\n",
    "    cat_idxs=cat_idxs,\n",
    "    cat_dims=cat_dims,\n",
    "    cat_emb_dim=1,\n",
    "    lambda_sparse=1e-4, momentum=0.3, clip_value=2.,\n",
    "    optimizer_fn=torch.optim.Adam,\n",
    "    optimizer_params=dict(lr=2e-2),\n",
    "    scheduler_fn=None , epsilon=1e-15\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "if os.getenv(\"CI\", False):\n",
    "    print(\"here\")\n",
    "# Take only a subsample to run CI\n",
    "    X_train = data[features].values[train_indices][:1000,:]\n",
    "    y_train = data[target].values[train_indices][:1000]\n",
    "else:\n",
    "    X_train = data[features].values[train_indices]\n",
    "    y_train = data[target].values[train_indices]\n",
    "\n",
    "X_valid = data[features].values[valid_indices]\n",
    "y_valid = data[target].values[valid_indices]\n",
    "\n",
    "X_test = data[features].values[test_indices]\n",
    "y_test = data[target].values[test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epochs = 50 if not os.getenv(\"CI\", False) else 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.22774 | train_accuracy: 0.05808 | valid_accuracy: 0.05714 |  0:00:34s\n",
      "epoch 1  | loss: 0.78388 | train_accuracy: 0.03543 | valid_accuracy: 0.0354  |  0:01:05s\n",
      "epoch 2  | loss: 0.73506 | train_accuracy: 0.0357  | valid_accuracy: 0.03559 |  0:01:37s\n",
      "epoch 3  | loss: 0.71173 | train_accuracy: 0.03585 | valid_accuracy: 0.03566 |  0:02:07s\n",
      "epoch 4  | loss: 0.69748 | train_accuracy: 0.03561 | valid_accuracy: 0.0355  |  0:02:35s\n",
      "epoch 5  | loss: 0.68411 | train_accuracy: 0.0356  | valid_accuracy: 0.0355  |  0:03:05s\n",
      "epoch 6  | loss: 0.67533 | train_accuracy: 0.12261 | valid_accuracy: 0.12381 |  0:03:34s\n",
      "epoch 7  | loss: 0.66557 | train_accuracy: 0.0635  | valid_accuracy: 0.06441 |  0:04:04s\n",
      "epoch 8  | loss: 0.65848 | train_accuracy: 0.08809 | valid_accuracy: 0.08809 |  0:04:34s\n",
      "epoch 9  | loss: 0.65074 | train_accuracy: 0.11824 | valid_accuracy: 0.11732 |  0:05:03s\n",
      "epoch 10 | loss: 0.64568 | train_accuracy: 0.20514 | valid_accuracy: 0.20543 |  0:05:33s\n",
      "epoch 11 | loss: 0.6487  | train_accuracy: 0.31186 | valid_accuracy: 0.31337 |  0:06:04s\n",
      "epoch 12 | loss: 0.64459 | train_accuracy: 0.41126 | valid_accuracy: 0.41105 |  0:06:32s\n",
      "epoch 13 | loss: 0.63493 | train_accuracy: 0.50328 | valid_accuracy: 0.50313 |  0:07:01s\n",
      "epoch 14 | loss: 0.62674 | train_accuracy: 0.5622  | valid_accuracy: 0.56134 |  0:07:29s\n",
      "epoch 15 | loss: 0.62497 | train_accuracy: 0.60859 | valid_accuracy: 0.60754 |  0:07:58s\n",
      "epoch 16 | loss: 0.6138  | train_accuracy: 0.66882 | valid_accuracy: 0.66682 |  0:08:27s\n",
      "epoch 17 | loss: 0.60691 | train_accuracy: 0.6789  | valid_accuracy: 0.67693 |  0:08:56s\n",
      "epoch 18 | loss: 0.60304 | train_accuracy: 0.70334 | valid_accuracy: 0.70176 |  0:09:25s\n",
      "epoch 19 | loss: 0.59642 | train_accuracy: 0.71004 | valid_accuracy: 0.70751 |  0:09:53s\n",
      "epoch 20 | loss: 0.59421 | train_accuracy: 0.73463 | valid_accuracy: 0.73111 |  0:10:22s\n",
      "epoch 21 | loss: 0.58394 | train_accuracy: 0.74142 | valid_accuracy: 0.73849 |  0:10:52s\n",
      "epoch 22 | loss: 0.58019 | train_accuracy: 0.74897 | valid_accuracy: 0.74723 |  0:11:21s\n",
      "epoch 23 | loss: 0.58674 | train_accuracy: 0.76186 | valid_accuracy: 0.75958 |  0:11:50s\n",
      "epoch 24 | loss: 0.5739  | train_accuracy: 0.77805 | valid_accuracy: 0.77492 |  0:12:18s\n",
      "epoch 25 | loss: 0.56883 | train_accuracy: 0.77476 | valid_accuracy: 0.77177 |  0:12:48s\n",
      "epoch 26 | loss: 0.56244 | train_accuracy: 0.78495 | valid_accuracy: 0.78254 |  0:13:18s\n",
      "epoch 27 | loss: 0.55281 | train_accuracy: 0.78796 | valid_accuracy: 0.7862  |  0:13:48s\n",
      "epoch 28 | loss: 0.55122 | train_accuracy: 0.79    | valid_accuracy: 0.78737 |  0:14:16s\n",
      "epoch 29 | loss: 0.55526 | train_accuracy: 0.79127 | valid_accuracy: 0.7882  |  0:14:45s\n",
      "epoch 30 | loss: 0.54734 | train_accuracy: 0.79381 | valid_accuracy: 0.7913  |  0:15:14s\n",
      "epoch 31 | loss: 0.53655 | train_accuracy: 0.79911 | valid_accuracy: 0.79638 |  0:15:44s\n",
      "epoch 32 | loss: 0.53442 | train_accuracy: 0.79906 | valid_accuracy: 0.79557 |  0:16:13s\n",
      "epoch 33 | loss: 0.53004 | train_accuracy: 0.80706 | valid_accuracy: 0.80502 |  0:16:42s\n",
      "epoch 34 | loss: 0.52312 | train_accuracy: 0.80412 | valid_accuracy: 0.80139 |  0:17:11s\n",
      "epoch 35 | loss: 0.52096 | train_accuracy: 0.81139 | valid_accuracy: 0.80715 |  0:17:41s\n",
      "epoch 36 | loss: 0.5121  | train_accuracy: 0.81126 | valid_accuracy: 0.80738 |  0:18:10s\n",
      "epoch 37 | loss: 0.5076  | train_accuracy: 0.80961 | valid_accuracy: 0.80527 |  0:18:39s\n",
      "epoch 38 | loss: 0.51198 | train_accuracy: 0.80848 | valid_accuracy: 0.80519 |  0:19:09s\n",
      "epoch 39 | loss: 0.50782 | train_accuracy: 0.81159 | valid_accuracy: 0.80757 |  0:19:44s\n",
      "epoch 40 | loss: 0.50502 | train_accuracy: 0.81615 | valid_accuracy: 0.81302 |  0:20:23s\n",
      "epoch 41 | loss: 0.49741 | train_accuracy: 0.82163 | valid_accuracy: 0.81757 |  0:21:03s\n",
      "epoch 42 | loss: 0.48999 | train_accuracy: 0.82395 | valid_accuracy: 0.82016 |  0:21:42s\n",
      "epoch 43 | loss: 0.48675 | train_accuracy: 0.82289 | valid_accuracy: 0.81867 |  0:22:22s\n",
      "epoch 44 | loss: 0.48541 | train_accuracy: 0.82923 | valid_accuracy: 0.82501 |  0:23:00s\n",
      "epoch 45 | loss: 0.48419 | train_accuracy: 0.82934 | valid_accuracy: 0.82548 |  0:23:39s\n",
      "epoch 46 | loss: 0.4731  | train_accuracy: 0.83203 | valid_accuracy: 0.82807 |  0:24:17s\n",
      "epoch 47 | loss: 0.46719 | train_accuracy: 0.83505 | valid_accuracy: 0.83038 |  0:24:56s\n",
      "epoch 48 | loss: 0.46405 | train_accuracy: 0.83569 | valid_accuracy: 0.83122 |  0:25:13s\n",
      "epoch 49 | loss: 0.45886 | train_accuracy: 0.84215 | valid_accuracy: 0.83726 |  0:25:27s\n",
      "Stop training because you reached max_epochs = 50 with best_epoch = 49 and best_valid_accuracy = 0.83726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MON PC\\AppData\\Roaming\\Python\\Python310\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    }
   ],
   "source": [
    "from pytorch_tabnet.augmentations import ClassificationSMOTE\n",
    "aug = ClassificationSMOTE(p=0.2)\n",
    "\n",
    "model.fit(\n",
    "    X_train=X_train, y_train=y_train,\n",
    "    eval_set=[(X_train, y_train), (X_valid, y_valid)],\n",
    "    eval_name=['train', 'valid'],\n",
    "    max_epochs=max_epochs, patience=100,\n",
    "    batch_size=16384, virtual_batch_size=256,\n",
    "    augmentations=aug\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x233957dd450>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot losses\n",
    "plt.plot(model.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2339579a9b0>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot accuracy\n",
    "plt.plot(model.history['train_accuracy'])\n",
    "plt.plot(model.history['valid_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST VALID SCORE FOR : 0.8372628874962081\n",
      "FINAL TEST SCORE FOR : 0.8396426942505787\n",
      "TABNET LOSS : 0.38437015447779066\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "preds_mapper = { idx : class_name for idx, class_name in enumerate(model.classes_)}\n",
    "\n",
    "preds_tabnet = model.predict_proba(X_test)\n",
    "\n",
    "#y_pred_tabnet = np.vectorize(preds_mapper.get)(np.argmax(preds_tabnet, axis=1))\n",
    "y_pred = np.argmax(preds_tabnet, axis=1)\n",
    "test_acc = accuracy_score(y_pred=y_pred, y_true=y_test)\n",
    "tab_loss = log_loss(y_test, preds_tabnet)\n",
    "print(f\"BEST VALID SCORE FOR : {model.best_cost}\")\n",
    "print(f\"FINAL TEST SCORE FOR : {test_acc}\")\n",
    "print(f\"TABNET LOSS : {tab_loss}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_valid = le.fit_transform(y_valid)\n",
    "y_test = le.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe,Trials\n",
    "\n",
    "def score(params):\n",
    "    print(\"Training with params: \")\n",
    "    print(params)\n",
    "    num_round = int(params['n_estimators'])\n",
    "    del params['n_estimators']\n",
    "    xgb  = XGBClassifier(params)\n",
    "    xgb.fit(X_train, \n",
    "            y_train, \n",
    "            early_stopping_rounds=5, \n",
    "            eval_set=[(X_train, y_train), (X_valid, y_valid), (X_test, y_test)])\n",
    "            \n",
    "    results = xgb.evals_result()\n",
    "    proba = xgb.predict_proba(X_test)\n",
    "    accuracy_ = accuracy_score(y_pred=np.argmax(proba,axis=1), y_true=y_test)\n",
    "    score = results['validation_2']['mlogloss'][-1]\n",
    "    \n",
    "    print(\"\\tScore {0}\\n\\n\".format(score))\n",
    "    return {'loss': score, 'status': STATUS_OK,\"accuracy\" : accuracy_}\n",
    "random_state = 0\n",
    "space = {\n",
    "        'n_estimators': hp.uniform('n_estimators', 100, 4000),\n",
    "        'eta': hp.loguniform('eta', 1e-7, 1),\n",
    "\n",
    "        'max_depth':  hp.quniform('max_depth', 1,10,1),\n",
    "        'min_child_weight': hp.loguniform('min_child_weight', 1e-16, 1e5),\n",
    "        'subsample': hp.uniform('subsample', 0.2, 1),\n",
    "        'gamma': hp.choice('gamma', [0, hp.loguniform('gamma_', 1e-16, 1e2) ]),\n",
    "        'colsample_bytree': hp.uniform('colsample_bytree', 0.2, 1),\n",
    "        'colsample_bylevel': hp.uniform('colsample_bylevel', 0.2, 1),\n",
    "        'alpha': hp.choice('alpha', [0, hp.loguniform('alpha_', 1e-16, 1e2) ]),\n",
    "        'lambda': hp.choice('lamda', [0, hp.loguniform('lambda_',1e-16, 1e2) ]),\n",
    "        'seed': random_state\n",
    "    }\n",
    "trials = Trials()\n",
    "# Use the fmin function from Hyperopt to find the best hyperparameters\n",
    "best = fmin(score, space, algo=tpe.suggest, \n",
    "                trials=trials, \n",
    "                max_evals=10)\n",
    "print(\"The best hyperparameters are: \", \"\\n\")\n",
    "print(best)\n",
    "# train with the best parameters\n",
    "xgb  = XGBClassifier(best)\n",
    "xgb.fit(X_train, \n",
    "            y_train, \n",
    "            early_stopping_rounds=5, \n",
    "            eval_set=[(X_train, y_train), (X_valid, y_valid), (X_test, y_test)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB accuracy :  0.8699775393062141\n",
      "XGB loss :  0.32675059816777635\n"
     ]
    }
   ],
   "source": [
    "#XGBoost loss & accuracy\n",
    "XGB_accuracy = [t[\"result\"][\"accuracy\"] for t in trials][-1]\n",
    "XGB_loss = [t[\"result\"][\"loss\"] for t in trials][-1]\n",
    "print(f\"XGB accuracy :  {XGB_accuracy}\")\n",
    "print(f\"XGB loss :  {XGB_loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge : Combining the XGB boost and the TabNet (The ensemble)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### prediction probabilities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the XGB predictions\n",
    "pred_XGB = xgb.predict_proba(X_test)\n",
    "#get the TabNet predictions\n",
    "pred_TabNet = model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Weighted by 1/2 (the mean of the predictions)\n",
    "$$\n",
    "Predictions = Argmax(\\frac{1}{2} Ã— TabNet\\_Test\\_predictions + \\frac{1}{2} Ã— XGB\\_test\\_Predictions) = Argmax(mean(TabNet\\_Test\\_predictions ,XGB\\_test\\_Predictions))\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8710532430315913"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weighted = (pred_XGB + pred_TabNet) / 2\n",
    "weighted_acuracy0 = accuracy_score(y_pred=np.argmax(weighted,axis=1), y_true=y_test)\n",
    "weighted_acuracy0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Weighted by the negative of the loss\n",
    "$$\n",
    "Predictions = Argmax(\\frac{-TabNet\\_Test\\_Loss Ã— TabNet\\_Test\\_predictions + -XGB\\_test\\_Loss Ã— XGB\\_test\\_Predictions}{-(TabNet\\_Test\\_Loss + XGB\\_test\\_Loss)})\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8690137087682762"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weighted = ((-XGB_loss * pred_XGB) + (-tab_loss * pred_TabNet)) / (-tab_loss -XGB_loss)\n",
    "weighted_acuracy1 = accuracy_score(y_pred=np.argmax(weighted,axis=1), y_true=y_test)\n",
    "weighted_acuracy1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Weighted by the accuracy\n",
    "$$\n",
    "Predictions = Argmax(\\frac{TabNet\\_test\\_accuracy Ã— TabNet\\_Test\\_predictions + XGB\\_test\\_accuracy Ã— XGB\\_test\\_Predictions}{TabNet\\_Test\\_Accuracy + XGB\\_test\\_accuracy})\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8715093414111512"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weighted = ((XGB_accuracy * pred_XGB) + (test_acc * pred_TabNet)) / (tab_loss + XGB_loss)\n",
    "weighted_acuracy2 = accuracy_score(y_pred=np.argmax(weighted,axis=1), y_true=y_test)\n",
    "weighted_acuracy2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Weighted by the loss inverse\n",
    "$$\n",
    "Predictions = Argmax(\\frac{\\frac{1}{TabNet\\_Test\\_Loss} Ã— TabNet\\_Test\\_predictions + \\frac{1}{XGB\\_test\\_Loss} Ã— XGB\\_test\\_Predictions}{\\frac{1}{TabNet\\_Test\\_Loss} + \\frac{1}{XGB\\_test\\_Loss}})\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8727657633623916"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weighted = (((1/XGB_loss) * pred_XGB) + ((1/tab_loss) * pred_TabNet)) / ((1/XGB_loss) + (1/tab_loss))\n",
    "weighted_acuracy3 = accuracy_score(y_pred=np.argmax(weighted,axis=1), y_true=y_test)\n",
    "weighted_acuracy3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Weighted by the loss & the accuracy\n",
    "$$\n",
    "Predictions = Argmax(\\frac{(-TabNet\\_test\\_loss + TabNet\\_test\\_accuracy ) Ã— TabNet\\_Test\\_predictions +(-XGB\\_test\\_loss + XGB\\_test\\_accuracy) Ã— XGB\\_test\\_Predictions}{(-XGB\\_test\\_loss + XGB\\_test\\_accuracy) + (-TabNet\\_test\\_loss + TabNet\\_test\\_accuracy )})\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8728776365498309"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weighted = (((-XGB_loss+XGB_accuracy) * pred_XGB) + ((-tab_loss + test_acc) * pred_TabNet)) / (-tab_loss + test_acc  - XGB_loss + XGB_accuracy )\n",
    "weighted_acuracy4 = accuracy_score(y_pred=np.argmax(weighted,axis=1), y_true=y_test)\n",
    "weighted_acuracy4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â••\n",
      "â”‚ model                                         â”‚ accuracy      â”‚ loss                â”‚\n",
      "â•žâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡\n",
      "â”‚ TabNet                                        â”‚ 0.8396        â”‚ 0.38437015447779066 â”‚\n",
      "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "â”‚ XGB boost                                     â”‚ 0.87          â”‚ 0.32675059816777635 â”‚\n",
      "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "â”‚ ensemble weighted by accuracy                 â”‚ 0.8715        â”‚ //                  â”‚\n",
      "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "â”‚ ensemble weighted by 1/2 (mean)               â”‚ 0.8711        â”‚ //                  â”‚\n",
      "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "â”‚ ensemble weighted by the negative of the loss â”‚ 0.869         â”‚ //                  â”‚\n",
      "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "â”‚ ensemble weighted by the loss inverse         â”‚ 0.8728        â”‚ //                  â”‚\n",
      "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "â”‚ ensemble weighted by the loss & accuracy      â”‚ 0.8729 (best) â”‚ //                  â”‚\n",
      "â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•›\n"
     ]
    }
   ],
   "source": [
    "table = [\n",
    "    [\"model\",\"accuracy\",\"loss\"],\n",
    "    [\"TabNet\",round(test_acc,4),tab_loss],\n",
    "    [\"XGB boost\",round(XGB_accuracy,4),XGB_loss],\n",
    "    [\"ensemble weighted by accuracy\",round(weighted_acuracy2,4),\"//\"],\n",
    "    [\"ensemble weighted by 1/2 (mean)\",round(weighted_acuracy0,4),\"//\"],\n",
    "    [\"ensemble weighted by the negative of the loss\",str(round(weighted_acuracy1,4)),\"//\"],\n",
    "    [\"ensemble weighted by the loss inverse\",str(round(weighted_acuracy3,4)),\"//\"],\n",
    "    [\"ensemble weighted by the loss & accuracy\",str(round(weighted_acuracy4,4)) + \" (best)\",\"//\"],\n",
    "]\n",
    "print(tabulate.tabulate(table, headers='firstrow', tablefmt='fancy_grid'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
